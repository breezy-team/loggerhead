======================================
Storing Partially Denormalized History
======================================

Storing graph data in a way that can be efficiently accessed can be difficult.
On the one hand, it is common to store data-per-node. This can be space
efficient. However, when performing queries you often have to walk
one-node-at-a-time which is inefficient. At the other end, you can store the
data fully denormalized (eg, for each revision X, you store X => all
ancestors), however that has quadratic growth. Also, while you want to avoid
worst-case behavior of looking one-at-a-time, you also want to avoid the
worst-case all-at-once behavior.

Finding a compromise between minimal data storage, and efficient queries seems
worth investigating.


Example: Dotted Revnos
======================

One example where this shows up clearly is in how we handle dotted revnos, and
"``merge_sorted``" data in general. It is generally a nice way to look at the
data (``bzr qlog``), but we'd like to avoid the O(all_history) aspect.

For dotted revnos, one option is to store data per revision versus its
mainline parent. This works well because the data is organised in such a
fashion anyway [#]_. For this example, I'll use the SQLite syntax, because it
is a concrete way of expressing the information.::

  CREATE TABLE revision (
    db_id INTEGER PRIMARY KEY AUTOINCREMENT,
    revision_id TEXT NOT NULL
  );
  CREATE INDEX revision_revision_id_index ON revision (revision_id);
  CREATE TABLE parent (
    child INTEGER REFERENCES revision NOT NULL,
    parent INTEGER REFERENCES revision NOT NULL,
    parent_idx INTEGER NOT NULL -- 0 == left-hand parent
  );
  CREATE INDEX parent_child_index ON parent (child);
  CREATE TABLE dotted_revnos (
    tip_revision INTEGER REFERENCES revision NOT NULL,
    merged_revision INTEGER REFERENCES revision NOT NULL,
    revno TEXT NOT NULL,
    end_of_merge BOOL NOT NULL,
    merge_depth INTEGER NOT NULL,
    CONSTRAINT dotted_revnos_key UNIQUE (tip_revision, merged_revision)
  );
  CREATE INDEX dotted_revnos_index ON dotted_revnos(tip_revision);
    

At this point, you can store the revision graph and the dotted revno
information. It should be fairly compact, since every record is only present
one time. However, it can be difficult to find the dotted revno for an
arbitrary branch tip. This is because you have to walk the parent table, in
order to find possible tip keys, in order to look for ``(tip_revision,
merged_revision)`` pairs.

Example: Given this graph, find the dotted revno for C (newest rev at top)::
  
  F
  |\
  D E
  |\|
  B C
  |/
  A

You start with F, and can query for (F, C), but that won't be present. So you
walk back through the parent table to find D, and then check for (D, C) which
can then be found. However, if there are a lot of mainline parent, this
takes a lot of walking in the parent table and for each step you have a
lookup into the ``dotted_revnos`` table.

The join you want to do is something like::

  SELECT revno FROM dotted_revnos
   WHERE tip_revision IN ''MAINLINE_ANCESTRY(F)''
     AND merged_revision = 'C';

The trick is to find a reasonable way of defining ``MAINLINE_ANCESTRY(F)``
that doesn't bloat into all-history for every revision, and doesn't require
you to try every revision one-at-a-time. My idea is that you can do ranges of
ancestry. You can observe that for related branches, most of the mainline
ancestry overlaps. So even if you have a large graph, most of the mainline
ancestors are the same. Here is are a couple more tables::

  CREATE TABLE mainline_parent_range (
    pkey INTEGER PRIMARY KEY AUTOINCREMENT,
    head INTEGER REFERENCES revision NOT NULL,
    tail INTEGER REFERENCES revision, -- NULL indicates start-of-history
    count INTEGER NOT NULL
  );
  CREATE INDEX mainline_parent_range_head_index
    ON mainline_parent_range (head);
  CREATE TABLE mainline_parent (
    range INTEGER REFERENCES mainline_parent_range NOT NULL,
    revision INTEGER REFERENCES revision NOT NULL,
    dist INTEGER NOT NULL -- Offset from head, so we know the order
    -- Not adding the constraint at this time, but it is logically there
    -- CONSTRAINT mainline_parent_rev_unique UNIQUE (range, revision)
  );
  CREATE INDEX mainline_parents_range_index
    ON mainline_parent (range);

The idea is that you can now do the query::

  SELECT revno FROM dotted_revnos, mainline_parent
   WHERE tip_revision = mainline_parent.revision
     AND mainline_parent.range = ?
     AND merged_revision = ?;

And you can reasonably efficiently find the appropriate ranges. You do this by
starting to walk the ``parents`` table, and queurying the
``mainline_parent_range`` table to see if you can start grabbing big sections.
at a time.::

    def revision_id_to_db_num(cursor, revision_id):
        return cursor.execute('SELECT db_id FROM revision'
                              ' WHERE revision_id = ?',
                              (revision_id,)).fetchone()[0]

    def get_dotted_revno(cursor, tip_revision_id, merged_revision_id):
        dotted_revno = None
        cur_tip_db_id = revision_id_to_db_num(tip_revision_id)
        merged_db_id = revision_id_to_db_num(merged_revision_id)
        
        while dotted_revno is None and cur_tip_db_id is not None:
            # Check for a range
            res = cursor.execute('''
                SELECT pkey, tail FROM mainline_parent_range, revision
                 WHERE head = revision.pkey
                   AND revision.revision_id = ?
                 LIMIT 1
                 ''', (cur_tip_db_id,)).fetchall()
            if len(res) == 0: # no such entry, step-by-one
                next_par = cursor.execute('''
                    SELECT parent.parent FROM parent
                     WHERE child = ?
                       AND parent_idx = 0
                    ''', (cur_tip_db_id,)).fetchone()
                if next_par is None:
                    next_tip_db_id = None
                else:
                    next_tip_db_id = next_par[0]
                res = cursor.execute('''
                    SELECT revno from dotted_revnos
                     WHERE tip_revision = ?
                       AND merged_revision = ?
                     LIMIT 1
                    ''', (cur_tip_db_id, merged_db_id)).fetchone()
            else: # entry, check against the range
                range_key, next_tip_db_id = res[0]
                res = cursor.execute('''
                    SELECT revno from dotted_revnos, mainline_parent
                     WHERE tip_revision = mainline_parent.revision
                       AND mainline_parent.range = ?
                       AND merged_revision = ?
                     LIMIT 1
                    ''', (range_key, merged_db_id)).fetchone()
            if res is not None:
                dotted_revno = res[0]
            cur_tip_db_id = next_tip_db_id
        return dotted_revno

The trick is now about how the ``mainline_parent`` table gets filled in. I
think doing some sort of batching, like every 100 revisions would be
reasonble. The other thing is to try to get convergence. If you imagine adding
a new branch, you can start walking back its mainline ancestry, and seeing if
there is already a range whose head is the current revision. If so, you can
just use that as your tail and stop.


Mapping Dotted Revnos to Revisions
==================================

Doing the reverse mapping is also tricky, because it depends on the current
tip definition. However, I think the same trick can be applied, by just
changing the inner query to::

  SELECT merged_revision FROM dotted_revnos, mainline_parent
   WHERE tip_revision = mainline_parent.revision
     AND mainline_parent.range = ?
     AND dotted_revno = ?

Note that this should be reasonably performant, even without adding another
index. The trick seems to be just getting the join between the
``mainline_parent`` table to be reasonable against the ``dotted_revnos``
table. Looking at it from a ``JOIN`` syntax, it is something like::

    SELECT * FROM dotted_revnos JOIN mainline_parent
               ON tip_revision = mainline_parent.revision

If I'm thinking correctly, that query should be fairly efficient at giving you
a subset of the graph, while still allowing you to store the nodes of the
graph in a fairly compact fashion. If there are revisions in branch A that are
then merged into branches B and C, then you end up with 2 entries in the
``dotted_revnos`` table. However, if B then gets merged into D, I'm pretty
sure you don't get new entries. So I think ``dotted_revnos`` ends up being
O(num_revisions*num_integration_branches), and the latter is usually a small
constant (say less than 5, and probably often only 1 or 2?). We should also
look at it with say the MySQL history, which because of there 'merge+push'
style of working would probably lead to expansion in the number of entries. It
still should be much better than a "ancestry of revision" table, that grows
O(num_revisions*num_revisions).


Ancestry vs Mainline
====================

We can probably do a similar 'cache groups' for whole-ancestry information,
versus just mainline information. However, the convergence at a single
``tail`` is not guaranteed, so more work would need to be investigated to
figure out how to get good overlap between various branches.


GDFO
====

Vincent makes a case for using ``(gdfo, revision_id)`` as a key. Which is that
you can query the database for "give me all revision_ids which have gdfo close
to my gdfo". The idea is that you can filter for say 100 parent revisions.
Some good bits:

 a) The data naturally clusters by ancestry, so direct parents are usually
    close to their children (on a similar page).
 b) You can request a range without having to walk for each one. (Though you
    do eventually have to walk to ensure that all gdfos in that range are
    actually part of the ancestry you are searching.)


Some downsides:

 a) Paths along the graph do not always follow particularly 'linearly'.
    Consider

     i) Branch 1 is a single patch against rev 1000.
     ii) The mainline is developed for 3 months, with lots of changes landing.
     iii) Branch 1 is updated with a second patch, and lands on mainline rev
          1100.
     iv) The parent here is going to have gdfo 1002, while the mainline has
         gdfo 1100. Thus gdfo doesn't immediately shortcut you from having to
         walk through all 100 revisions, and you lose a lot of assistance for
         both (a) and (b) listed above.
 b) You need to now know gdfo to get into the graph at all, rather than just
    revision_id. (This can be solved with stuff like the branch/last_revision
    file storing the gdfo.)
 c) gdfo's change when ghosts are filled in. Albiet rare, it means that (b) is
    potentially a more difficult problem. As 2 repos with the same revision
    but different ghosts will have different gdfo values for that revision.

.. [#] Dotted revnos are numbered based on the current branch tip revision.
   However, there is a stability guarantee that we can exploit. If a revision
   X is in the ancestry of tip T, then the dotted revno for X will be the same
   for all descendents of T.


Partial ``merge_sort`` Computation
==================================

This section tries to discuss the issues and design of how to compute dotted
revnos and the overal merge-sorted graph, given a desire to avoid walking all
history.

The current merge-sorted design is achieved by walking the ancestry graph. A
'pending' stack is created. Parents are put on the stack, with the left-most
parent at the top of the stack. Once all parents have been put into pending,
the top node can is ready to be numbered and can be removed. For example::

  A
  |\
  B C
  |/|
  D E
  | |
  | F
  |/
  G

G is first pushed onto the stack. We then push F and D onto the stack (GFD).
We then go to D, and push C and B (GFDCB). And then go to B and push A. When
we get to A (GFDCBA), there are no more parents, so A is ready to be numbered
(0, 0, 1), and it is popped off and marked completed. After that we get to B,
which is also complete (0, 0, 2). C is also ready. When we pushed it, we noted
that it was a right-hand parent, so its ``merge_depth`` gets incremented by 1
vs the original depth of 0. Thus it needs a dotted revno, and gets (1, 1, 1).
D is then ready to be marked (0, 0, 3). When we get to F, we have to push its
parent E onto the stack (GFE), when we switch to E, we see its parents are
already numbered, and it gets (1, 1, 2). F is then ready and gets (1, 1, 3). G
is then the last entry and gets (0, 0, 4). As a simplification, all numbers
starting with (0, 0, ?) get truncated down to just (?,).

Difficulties
------------

The main difficulties I see are determining:
  1) First child
  2) ``_revno_to_branch_count``

The former is used to determine whether we do a simple last-digit update
(1,1,1) => (1,1,2), or whether we have to allocate a new branch number. Both
values are restricted to the current ancestry (so it cannot be simply cached),
also, complex ancestries make it difficult to track. Consider::

  A
  |\
  | \
  |  \
  |   B
  |  /|
  | C E
  |/ X
  D / G
  |/ /|
  F H I
  | |/
  | J
  |/
  K

In this case, the numbers are::

    A 1
    B 1.1.1
    C 1.1.2
    D 2
    E 1.2.1
    F 3
    G 1.1.3
    H 1.1.4
    I 1.3.1
    J 1.1.5
    K 4

The tricks are that G is still the first child with C as a left-hand parent,
so it continues the simple sequence. E lands into mainline before I, so I gets
bumped to the next available branch number, which ends up being 3 (not a
simple increment from its parent G).

It should be possible to generate a 'bounds' for the ancestry we need to look
at, though. Specifically, we know that C landed in D and I landed in K. Thus
we only need to look at revisions that landed in D, F, K. If it landed before
D, then C's number would be higher. If it lands after K, then it doesn't
matter for I. We do need to consider all the revs in D, though, because of
stuff like::

  A
  |\
  | \
  |  \
  |   B
  |  /|
  | C D
  | |X
  | E G
  |/ /|
  F H I
  | |/
  | J
  |/
  K

In the above, D causes a bump to the branch number that I needs to be aware
of.
      
Avoiding All Ancestry
---------------------

The other trick is that when we see a new merge, how *much* of the ancestry do
we need to bring in. It should be possible to use a couple tricks to limit the
range.

 1) gdfo. In the graph directly above, the gdfo numberings are::

      1   A
      2   B
      3   C D
      4   E G
      5   F H I
      6   J
      7   K

    This doesn't help a huge amount, because I think we still need to walk the
    mainline back to A. Because while walking the left-hand ancestry of K, we
    get back to G with gdfo of 4. Because gdfo(G) < gdfo(F) it could have been
    merged there. We don't have to read the ancestry of A, though.

 2) 'known children'. There is another complication when you have a new 'root'
    ancestry.  Consider::

      :
      A
      |
      B C
      | |
      | D
      |/
      E

    C is a new line of development (or a ghost), which ends up with a
    gdfo(C)=1.  As such, we would potentially have to walk the whole ancestry
    priory to A, until we get back to the root revision. Because C *could
    have* been merged into any of them.

    One possibility is to notice that the only known child of C is D, which is a
    revision we are already including in our ancestry search. Note that this
    probably should also cover slightly more complex cases like::

      :
      A
      |
      B C
      | |\
      | D E
      | |/
      | F
      |/
      G

    Where the descendants of C are not trivial, but they are 'contained'. Note
    that probing for known children should be a simple index lookup (``SELECT
    child FROM parent WHERE parent=?``). However, that can give answers
    outside of the scope of the ancestry we currently care about. eg, in the
    above example, if E did not merge into F, but instead merged into a
    descendant (H) of G. It would not affect the numbering of C,D,F. Then
    again, if we walked the children of E and saw that the gdfo of H was >
    gdfo(G) then we could also prune that as uninteresting. Actually, as long
    as gdfo(H) > the mainline ancestry we have searched so far, we should be
    done.

    One possible way to implement the search would be to start at G. In step
    1, we can find B and F. We should know that B is on the mainline, so we
    focus on F. Our current bounds for 'interesting' children is < gdfo(B). We
    lookup known children of F, and find only G, so the bounds set by B is
    sufficient.  We then walk back to D & E. The bounds set by B is still
    sufficient, since there are no interesting outbound links for either
    revision. (gdfo(F) < gdfo(B), however F is already marked as not having an
    children with gdfo(child) < gdfo(B).) As such, both D and E should get
    marked that their children ancestry is satisfied, similarly walking to C
    finishes the result.

 3) Combining the two, lets look again at::

      A
      |\
      | \
      |  \
      |   B
      |  /|
      | C D
      | |X
      | E G
      |/ /|\
      F H I :
      | |/
      | J
      |/
      K

    Starting at K, we grab F & J. gdfo(F) = 5. gdfo(K) = 7, gdfo(J) = 6. Since
    gdfo(J) = 6, we know that it cannot be merged into F (nor can any of its
    descendents). So J gets marked as "interesting" (it is an ancestor of K),
    but "complete" (it could not have been merged into a mainline revision
    that we have not fetched).
    
    Next we step to H & I, both with gdfo = 5.  These also get marked
    "interesting & complete". We then walk to G gdfo=4.  We check the known
    children of G, and see that they are all marked either complete, or have
    gdfo >= 5 (the hypothetical children off of ':' all have to have gdfo >=
    5.) The only other possible answer here would be that F was an immediate
    descendent of G. G then gets marked "interesting & complete".  We then
    walk to C gdfo=3. We then see that C has a child E that is not interesting
    & complete, and has a gdfo < 5. We could probably take a couple different
    tacks.

      a) Walk children of E until we see that it either reaches gdfo >= 5, or
         is, in fact, and ancestor of F (as is the case here). Or
      b) Step F's dotted_revno information, loading all of its ancestors, and
         setting the new gdfo threshold to A (1). At the same time, we can
         mark all of the ancestors as 'not interesting' because we know they
         are ancestors of F.

    I don't have a great feeling for (a) vs (b). On the one hand, we will need
    to page in the dotted_revno info anyway, because we'll use it to generate
    the revnos for G, etc.

..
  vim: ft=rst tw=78 ai

